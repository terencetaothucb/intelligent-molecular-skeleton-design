{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a3827cb-b3f4-48fb-baa7-dd22d558cd3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import shap\n",
    "import pickle\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import VotingRegressor \n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from joblib import Parallel, delayed\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2668748f-96cb-4e66-bdcf-7c818321b36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('')\n",
    "X = data.iloc[:,1:-1]\n",
    "Y = data.iloc[:,-1]\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f56688b-225a-425f-a1f4-54e7cfc4aabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_Valid = KFold(n_splits=3, shuffle=True, random_state=0)\n",
    "\n",
    "# Define a hyperparameter grid.\n",
    "parameter_LR = {\n",
    "}\n",
    "\n",
    "parameter_RR = {\n",
    "}\n",
    "\n",
    "parameter_LAR = {\n",
    "}\n",
    "\n",
    "parameter_ENR = {\n",
    "}\n",
    "\n",
    "parameter_PLSR = {\n",
    "}\n",
    "\n",
    "parameter_SVR = {\n",
    "}\n",
    "\n",
    "# Define model dictionary\n",
    "estimators = {\n",
    "    'LR': LinearRegression(),\n",
    "    'RR': Ridge(),\n",
    "    'LAR': Lasso(),\n",
    "    'ENR': ElasticNet(),\n",
    "    'PLSR': PLSRegression(),\n",
    "    'SVR': SVR()\n",
    "}\n",
    "\n",
    "# Map model names to corresponding hyperparameters.\n",
    "params_mapping = {\n",
    "    'LR': parameter_LR,\n",
    "    'RR': parameter_RR,\n",
    "    'LAR': parameter_LAR,\n",
    "    'ENR': parameter_ENR,\n",
    "    'PLSR': parameter_PLSR,\n",
    "    'SVR': parameter_SVR\n",
    "}\n",
    "\n",
    "grid_searches = {}\n",
    "for name, estimator in estimators.items():\n",
    "    params = params_mapping[name]\n",
    "    grid_searches[name] = GridSearchCV(estimator, params, scoring='r2', cv=cross_Valid, n_jobs=-1)\n",
    "\n",
    "# Train the model and find the best parameters.\n",
    "for name, grid in grid_searches.items():\n",
    "    grid.fit(x_train, y_train)\n",
    "    print(f\"{name} best parameters: {grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d03de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model dictionary initialization function\n",
    "def initialize_best_estimators(grid_searches):\n",
    "    return {\n",
    "        'LR': LinearRegression(**grid_searches['LR'].best_params_),\n",
    "        'RR': Ridge(**grid_searches['RR'].best_params_),\n",
    "        'LAR': Lasso(**grid_searches['LAR'].best_params_),\n",
    "        'ENR': ElasticNet(**grid_searches['ENR'].best_params_),\n",
    "        'PLSR': PLSRegression(**grid_searches['PLSR'].best_params_),\n",
    "        'SVR': SVR(**grid_searches['SVR'].best_params_)\n",
    "    }\n",
    "\n",
    "# Define a function to calculate the performance and characteristic coefficients of the computational model.\n",
    "def evaluate_models(seed, X, Y, grid_searches, submodel_r2_sums, submodel_rmse_sums, submodel_intercepts, num_seeds):\n",
    "    cross_validator = KFold(n_splits=2, shuffle=True, random_state=seed)\n",
    "    best_estimators = initialize_best_estimators(grid_searches)\n",
    "\n",
    "    # Create VotingRegressor\n",
    "    submodels = [(name, estimator) for name, estimator in best_estimators.items() if estimator is not None]\n",
    "    voting_regressor = VotingRegressor(submodels)\n",
    "\n",
    "    # Calculate the mean values of R2 and RMSE for each submodel.\n",
    "    submodel_r2_means = {}\n",
    "    submodel_rmse_means = {}\n",
    "    rmse_scorer = make_scorer(mean_squared_error, squared=False)\n",
    "    \n",
    "    # Used to store the feature coefficients of each model.\n",
    "    submodel_feature_coefs = {}\n",
    "    feature_coefs_weighted_sum = np.zeros(X.shape[1])\n",
    "    total_r2 = 0\n",
    "\n",
    "    for name, estimator in submodels:\n",
    "        r2_scores = cross_val_score(estimator, X, Y, cv=cross_validator, scoring='r2', n_jobs=-1)\n",
    "        rmse_scores = cross_val_score(estimator, X, Y, cv=cross_validator, scoring=rmse_scorer, n_jobs=-1)\n",
    "        submodel_r2_means[name] = np.mean(r2_scores)\n",
    "        submodel_rmse_means[name] = np.mean(rmse_scores)\n",
    "        submodel_r2_sums[name] += submodel_r2_means[name]\n",
    "        submodel_rmse_sums[name] += submodel_rmse_means[name]\n",
    "\n",
    "        # Fit the model to obtain feature coefficients and intercepts.\n",
    "        estimator.fit(X, Y)\n",
    "        coefs = estimator.coef_.flatten()\n",
    "        intercept = estimator.intercept_\n",
    "        submodel_intercepts[name] += intercept / num_seeds\n",
    "        \n",
    "        submodel_feature_coefs[name] = dict(zip(X.columns, coefs))\n",
    "        feature_coefs_weighted_sum += coefs * submodel_r2_means[name]\n",
    "        total_r2 += submodel_r2_means[name]\n",
    "\n",
    "    # Calculate the mean R2 and weighted RMSE of the fusion model.\n",
    "    voting_regressor_r2_mean = np.mean(cross_val_score(voting_regressor, X, Y, cv=cross_validator, scoring='r2', n_jobs=-1))\n",
    "    voting_regressor_rmse_mean = np.mean(cross_val_score(voting_regressor, X, Y, cv=cross_validator, scoring=rmse_scorer, n_jobs=-1))\n",
    "\n",
    "    # Calculate weighted feature coefficients\n",
    "    weighted_feature_coefs = feature_coefs_weighted_sum / total_r2 if total_r2 != 0 else feature_coefs_weighted_sum\n",
    "\n",
    "    weighted_feature_coefs_dict = dict(zip(X.columns, weighted_feature_coefs))\n",
    "\n",
    "    return {\n",
    "        'submodel_r2_means': submodel_r2_means,\n",
    "        'submodel_rmse_means': submodel_rmse_means,\n",
    "        'voting_regressor_r2_mean': voting_regressor_r2_mean,\n",
    "        'voting_regressor_rmse_mean': voting_regressor_rmse_mean,\n",
    "        'submodel_feature_coefs': submodel_feature_coefs,\n",
    "        'weighted_feature_coefs': weighted_feature_coefs_dict\n",
    "    }\n",
    "\n",
    "# Define and save the results of all seeds.\n",
    "all_results = []\n",
    "seeds = range(100)\n",
    "\n",
    "# Initialize the sum of R2 and RMSE of submodels.\n",
    "submodel_r2_sums = {name: 0.0 for name in initialize_best_estimators(grid_searches).keys()}\n",
    "submodel_rmse_sums = {name: 0.0 for name in initialize_best_estimators(grid_searches).keys()}\n",
    "\n",
    "# Initialize the sum of intercepts of submodels.\n",
    "submodel_intercepts = {name: 0.0 for name in initialize_best_estimators(grid_searches).keys()}\n",
    "\n",
    "# Initialize the weighted feature coefficient sum of the fusion model.\n",
    "weighted_feature_coefs_sums = np.zeros(len(X.columns))\n",
    "\n",
    "# Iterate through seeds and save results.\n",
    "for seed in seeds:\n",
    "    result = evaluate_models(seed, X, Y, grid_searches, submodel_r2_sums, submodel_rmse_sums, submodel_intercepts, len(seeds))\n",
    "    all_results.append(result)\n",
    "    weighted_feature_coefs_sums += np.array(list(result['weighted_feature_coefs'].values()))\n",
    "    print(f\"\")\n",
    "    print(f\"Seed {seed} - Voting Regressor R2 Mean: {result['voting_regressor_r2_mean']}, RMSE Mean: {result['voting_regressor_rmse_mean']}\")\n",
    "    print(\"Submodel R2 and RMSE Means:\")\n",
    "    for name in result['submodel_r2_means'].keys():\n",
    "        print(f\"{name}: R2 Mean = {result['submodel_r2_means'][name]}, RMSE Mean = {result['submodel_rmse_means'][name]}\")\n",
    "\n",
    "# Calculate the average value of the weighted feature coefficients of the fusion model for all seeds.\n",
    "avg_weighted_feature_coefs = weighted_feature_coefs_sums / len(seeds)\n",
    "\n",
    "# Calculate the weighted average intercept of all seeds.\n",
    "avg_weighted_intercept = sum(submodel_intercepts[name] for name in submodel_intercepts.keys()) / len(submodel_intercepts.keys())\n",
    "\n",
    "# Bind the feature names and corresponding weighted feature coefficients, and sort them in descending order of importance.\n",
    "sorted_feature_coefs = sorted(zip(X.columns, avg_weighted_feature_coefs), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Output the average R2, RMSE of the fusion model and the sorted feature coefficients.\n",
    "avg_voting_regressor_r2_mean = np.mean([result['voting_regressor_r2_mean'] for result in all_results])\n",
    "avg_voting_regressor_rmse_mean = np.mean([result['voting_regressor_rmse_mean'] for result in all_results])\n",
    "\n",
    "print(f\"\")\n",
    "print(f\"Average Voting Regressor R2 Mean: {avg_voting_regressor_r2_mean}\")\n",
    "print(f\"Average Voting Regressor Weighted RMSE Mean: {avg_voting_regressor_rmse_mean}\")\n",
    "print(\"Average Submodel R2 and RMSE Means:\")\n",
    "for name in submodel_r2_sums.keys():\n",
    "    print(f\"{name}: R2 Mean = {submodel_r2_sums[name] / len(seeds)}, RMSE Mean = {submodel_rmse_sums[name] / len(seeds)}\")\n",
    "\n",
    "# Draw a bar chart of feature coefficients.\n",
    "features, coefs = zip(*sorted_feature_coefs)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(x=list(coefs), y=list(features))\n",
    "plt.xlabel('Feature Coefficients')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Coefficients Sorted by Importance')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average Weighted Intercept: {avg_weighted_intercept}\")\n",
    "print(\"Sorted Feature Coefficients:\")\n",
    "for feature, coef in sorted_feature_coefs:\n",
    "    print(f\"{feature}: {coef}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
